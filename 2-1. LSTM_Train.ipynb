{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 6344,
     "status": "ok",
     "timestamp": 1736816975834,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "RcPpb0t6yau8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 948,
     "status": "ok",
     "timestamp": 1736816979723,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "F56DvJR2yavA"
   },
   "outputs": [],
   "source": [
    "# LSTM_Live 폴더의 모든 CSV 파일 병합\n",
    "def LSTM_Live_Merge(folder_path):\n",
    "    \"\"\"\n",
    "    폴더 및 하위 폴더에 있는 모든 CSV 파일을 로드하여 하나의 DataFrame으로 병합합니다.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): CSV 파일이 저장된 폴더 경로.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 병합된 DataFrame.\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "\n",
    "    # 하위 폴더까지 탐색\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                csv_path = os.path.join(root, file)\n",
    "                \n",
    "                # CSV 불러오기\n",
    "                df = pd.read_csv(csv_path)\n",
    "                csv_files.append(df)\n",
    "\n",
    "    # 모든 CSV 파일 병합\n",
    "    if csv_files:\n",
    "        combined_df = pd.concat(csv_files, ignore_index=True)\n",
    "        print(f\"총 {len(csv_files)}개의 CSV 파일을 병합했습니다. 데이터 크기: {combined_df.shape}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"병합할 CSV 파일이 없습니다.\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"자연스러운 정렬을 위한 키 생성 함수\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def LSTM_Capture_Merge(folder_path, sequence):\n",
    "    \"\"\"\n",
    "    폴더 및 하위 폴더에 있는 모든 CSV 파일을 폴더 및 파일명 기준 오름차순으로 로드하여 하나의 DataFrame으로 병합합니다.\n",
    "    단, CSV 파일의 개수가 sequence의 배수인 폴더만 병합합니다.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): CSV 파일이 저장된 폴더 경로.\n",
    "        sequence (int): CSV 파일 개수가 이 수의 배수여야 병합합니다.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 병합된 DataFrame.\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "\n",
    "    for root, _, files in sorted(os.walk(folder_path), key=lambda x: natural_sort_key(x[0])):\n",
    "        sorted_files = sorted([file for file in files if file.endswith('.csv')], key=natural_sort_key)\n",
    "        file_count = len(sorted_files)\n",
    "        \n",
    "        if file_count == 0:\n",
    "            continue  # CSV 파일이 없는 폴더는 건너뜀\n",
    "        \n",
    "        if file_count % sequence != 0:\n",
    "            print(f\"[제외] {root}: CSV 파일 수 {file_count}개는 {sequence}의 배수가 아닙니다.\")\n",
    "            continue  # sequence의 배수가 아니면 병합 제외\n",
    "\n",
    "        for file in sorted_files:\n",
    "            csv_path = os.path.join(root, file)\n",
    "            csv_files.append(csv_path)\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"병합할 CSV 파일이 없습니다.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # CSV 파일 병합 (float_precision 추가)\n",
    "    dataframes = [pd.read_csv(file, float_precision='round_trip') for file in csv_files]\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"총 {len(csv_files)}개의 CSV 파일을 병합했습니다. 데이터 크기: {combined_df.shape}\")\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736816981402,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "XCctZO0JEt3_"
   },
   "outputs": [],
   "source": [
    "# 데이터 시퀀스별로 변환\n",
    "def reshape_to_sequences(data, labels, seq_length):\n",
    "    \"\"\"\n",
    "    데이터를 시퀀스 형태로 변환합니다.\n",
    "    Args:\n",
    "        data (np.array): 키포인트 데이터.\n",
    "        labels (np.array): 레이블 데이터.\n",
    "        seq_length (int): 시퀀스 길이.\n",
    "    Returns:\n",
    "        np.array, np.array: 시퀀스화된 입력 데이터와 레이블.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        sequence_labels.append(labels[i + seq_length - 1])  # 시퀀스의 마지막 레이블 사용\n",
    "    return np.array(sequences), np.array(sequence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7399,
     "status": "ok",
     "timestamp": 1736816993226,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "v9lYaWtICsyN",
    "outputId": "5674cacd-ed53-49a6-8117-5ae8b539a54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 51개의 CSV 파일을 병합했습니다. 데이터 크기: (1476, 35)\n",
      "총 6개의 CSV 파일을 병합했습니다. 데이터 크기: (6, 35)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 및 병합\n",
    "folder_path = './Data'  # 데이터 폴더 경로\n",
    "df_live = LSTM_Live_Merge(folder_path + '/LSTM_Live') # LSTM_Live 폴더 병합\n",
    "df_capture = LSTM_Capture_Merge(folder_path + '/LSTM_Capture', sequence=3) # LSTM_Capture 폴더 병합\n",
    "df= pd.concat([df_live, df_capture], ignore_index=True) # 전체 폴더 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kp0_x</th>\n",
       "      <th>kp0_y</th>\n",
       "      <th>kp1_x</th>\n",
       "      <th>kp1_y</th>\n",
       "      <th>kp2_x</th>\n",
       "      <th>kp2_y</th>\n",
       "      <th>kp3_x</th>\n",
       "      <th>kp3_y</th>\n",
       "      <th>kp4_x</th>\n",
       "      <th>kp4_y</th>\n",
       "      <th>...</th>\n",
       "      <th>kp12_y</th>\n",
       "      <th>kp13_x</th>\n",
       "      <th>kp13_y</th>\n",
       "      <th>kp14_x</th>\n",
       "      <th>kp14_y</th>\n",
       "      <th>kp15_x</th>\n",
       "      <th>kp15_y</th>\n",
       "      <th>kp16_x</th>\n",
       "      <th>kp16_y</th>\n",
       "      <th>action_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>504.748352</td>\n",
       "      <td>174.018814</td>\n",
       "      <td>515.478699</td>\n",
       "      <td>165.320679</td>\n",
       "      <td>496.802307</td>\n",
       "      <td>164.987915</td>\n",
       "      <td>533.271973</td>\n",
       "      <td>169.938446</td>\n",
       "      <td>486.754608</td>\n",
       "      <td>168.247803</td>\n",
       "      <td>...</td>\n",
       "      <td>323.480652</td>\n",
       "      <td>517.671753</td>\n",
       "      <td>398.759491</td>\n",
       "      <td>472.511292</td>\n",
       "      <td>389.608002</td>\n",
       "      <td>501.476654</td>\n",
       "      <td>457.165405</td>\n",
       "      <td>478.328369</td>\n",
       "      <td>440.453247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>493.893311</td>\n",
       "      <td>167.112579</td>\n",
       "      <td>505.612885</td>\n",
       "      <td>158.779816</td>\n",
       "      <td>486.140564</td>\n",
       "      <td>158.240402</td>\n",
       "      <td>522.142822</td>\n",
       "      <td>168.031372</td>\n",
       "      <td>475.116486</td>\n",
       "      <td>165.450317</td>\n",
       "      <td>...</td>\n",
       "      <td>332.408905</td>\n",
       "      <td>514.570679</td>\n",
       "      <td>405.486908</td>\n",
       "      <td>458.247192</td>\n",
       "      <td>400.161682</td>\n",
       "      <td>509.301849</td>\n",
       "      <td>452.652832</td>\n",
       "      <td>473.916595</td>\n",
       "      <td>442.841217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489.443970</td>\n",
       "      <td>184.714722</td>\n",
       "      <td>501.096130</td>\n",
       "      <td>175.484283</td>\n",
       "      <td>481.513306</td>\n",
       "      <td>174.429993</td>\n",
       "      <td>520.108032</td>\n",
       "      <td>178.772324</td>\n",
       "      <td>471.632446</td>\n",
       "      <td>175.447479</td>\n",
       "      <td>...</td>\n",
       "      <td>340.180481</td>\n",
       "      <td>506.248840</td>\n",
       "      <td>416.903564</td>\n",
       "      <td>466.605835</td>\n",
       "      <td>407.960449</td>\n",
       "      <td>495.446808</td>\n",
       "      <td>452.529724</td>\n",
       "      <td>478.228882</td>\n",
       "      <td>438.963867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504.438934</td>\n",
       "      <td>182.662781</td>\n",
       "      <td>514.850159</td>\n",
       "      <td>173.607452</td>\n",
       "      <td>496.023224</td>\n",
       "      <td>172.890991</td>\n",
       "      <td>530.308594</td>\n",
       "      <td>177.233246</td>\n",
       "      <td>484.224304</td>\n",
       "      <td>175.232208</td>\n",
       "      <td>...</td>\n",
       "      <td>326.477722</td>\n",
       "      <td>520.327271</td>\n",
       "      <td>397.660522</td>\n",
       "      <td>466.075043</td>\n",
       "      <td>391.556549</td>\n",
       "      <td>504.693970</td>\n",
       "      <td>446.558716</td>\n",
       "      <td>474.512299</td>\n",
       "      <td>441.921783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>506.670929</td>\n",
       "      <td>164.630676</td>\n",
       "      <td>516.756531</td>\n",
       "      <td>157.412125</td>\n",
       "      <td>498.996033</td>\n",
       "      <td>156.697311</td>\n",
       "      <td>531.835144</td>\n",
       "      <td>160.829529</td>\n",
       "      <td>487.479858</td>\n",
       "      <td>158.457733</td>\n",
       "      <td>...</td>\n",
       "      <td>311.421844</td>\n",
       "      <td>515.506836</td>\n",
       "      <td>383.558777</td>\n",
       "      <td>476.523590</td>\n",
       "      <td>371.399200</td>\n",
       "      <td>506.702728</td>\n",
       "      <td>436.349396</td>\n",
       "      <td>487.770660</td>\n",
       "      <td>414.044739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>284.087372</td>\n",
       "      <td>120.812088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>170.815277</td>\n",
       "      <td>290.997467</td>\n",
       "      <td>196.064270</td>\n",
       "      <td>291.476349</td>\n",
       "      <td>192.157150</td>\n",
       "      <td>307.372986</td>\n",
       "      <td>226.044540</td>\n",
       "      <td>304.511932</td>\n",
       "      <td>220.732727</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>291.872925</td>\n",
       "      <td>124.161087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>173.845215</td>\n",
       "      <td>295.106537</td>\n",
       "      <td>199.819305</td>\n",
       "      <td>294.047119</td>\n",
       "      <td>193.109634</td>\n",
       "      <td>307.697021</td>\n",
       "      <td>230.016510</td>\n",
       "      <td>303.347900</td>\n",
       "      <td>220.787003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>252.043289</td>\n",
       "      <td>109.688896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248.737198</td>\n",
       "      <td>107.836449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>151.474121</td>\n",
       "      <td>251.780411</td>\n",
       "      <td>175.948883</td>\n",
       "      <td>247.387833</td>\n",
       "      <td>175.644180</td>\n",
       "      <td>255.462875</td>\n",
       "      <td>205.097855</td>\n",
       "      <td>252.283371</td>\n",
       "      <td>204.398911</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>254.473282</td>\n",
       "      <td>112.512146</td>\n",
       "      <td>256.610779</td>\n",
       "      <td>110.128609</td>\n",
       "      <td>251.741089</td>\n",
       "      <td>110.181183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>247.274139</td>\n",
       "      <td>111.595650</td>\n",
       "      <td>...</td>\n",
       "      <td>155.516266</td>\n",
       "      <td>254.698898</td>\n",
       "      <td>180.479706</td>\n",
       "      <td>249.408005</td>\n",
       "      <td>179.833176</td>\n",
       "      <td>261.246094</td>\n",
       "      <td>204.217148</td>\n",
       "      <td>259.570312</td>\n",
       "      <td>204.109390</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>249.178070</td>\n",
       "      <td>112.621239</td>\n",
       "      <td>250.664490</td>\n",
       "      <td>110.281746</td>\n",
       "      <td>246.259750</td>\n",
       "      <td>110.846107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>241.469635</td>\n",
       "      <td>112.262108</td>\n",
       "      <td>...</td>\n",
       "      <td>154.597092</td>\n",
       "      <td>253.565445</td>\n",
       "      <td>177.212082</td>\n",
       "      <td>253.720291</td>\n",
       "      <td>178.292694</td>\n",
       "      <td>263.932465</td>\n",
       "      <td>202.223892</td>\n",
       "      <td>263.420746</td>\n",
       "      <td>202.218918</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           kp0_x       kp0_y       kp1_x       kp1_y       kp2_x       kp2_y  \\\n",
       "0     504.748352  174.018814  515.478699  165.320679  496.802307  164.987915   \n",
       "1     493.893311  167.112579  505.612885  158.779816  486.140564  158.240402   \n",
       "2     489.443970  184.714722  501.096130  175.484283  481.513306  174.429993   \n",
       "3     504.438934  182.662781  514.850159  173.607452  496.023224  172.890991   \n",
       "4     506.670929  164.630676  516.756531  157.412125  498.996033  156.697311   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1477    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1478    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1479  252.043289  109.688896    0.000000    0.000000  248.737198  107.836449   \n",
       "1480  254.473282  112.512146  256.610779  110.128609  251.741089  110.181183   \n",
       "1481  249.178070  112.621239  250.664490  110.281746  246.259750  110.846107   \n",
       "\n",
       "           kp3_x       kp3_y       kp4_x       kp4_y  ...      kp12_y  \\\n",
       "0     533.271973  169.938446  486.754608  168.247803  ...  323.480652   \n",
       "1     522.142822  168.031372  475.116486  165.450317  ...  332.408905   \n",
       "2     520.108032  178.772324  471.632446  175.447479  ...  340.180481   \n",
       "3     530.308594  177.233246  484.224304  175.232208  ...  326.477722   \n",
       "4     531.835144  160.829529  487.479858  158.457733  ...  311.421844   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "1477  284.087372  120.812088    0.000000    0.000000  ...  170.815277   \n",
       "1478  291.872925  124.161087    0.000000    0.000000  ...  173.845215   \n",
       "1479    0.000000    0.000000    0.000000    0.000000  ...  151.474121   \n",
       "1480    0.000000    0.000000  247.274139  111.595650  ...  155.516266   \n",
       "1481    0.000000    0.000000  241.469635  112.262108  ...  154.597092   \n",
       "\n",
       "          kp13_x      kp13_y      kp14_x      kp14_y      kp15_x      kp15_y  \\\n",
       "0     517.671753  398.759491  472.511292  389.608002  501.476654  457.165405   \n",
       "1     514.570679  405.486908  458.247192  400.161682  509.301849  452.652832   \n",
       "2     506.248840  416.903564  466.605835  407.960449  495.446808  452.529724   \n",
       "3     520.327271  397.660522  466.075043  391.556549  504.693970  446.558716   \n",
       "4     515.506836  383.558777  476.523590  371.399200  506.702728  436.349396   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1477  290.997467  196.064270  291.476349  192.157150  307.372986  226.044540   \n",
       "1478  295.106537  199.819305  294.047119  193.109634  307.697021  230.016510   \n",
       "1479  251.780411  175.948883  247.387833  175.644180  255.462875  205.097855   \n",
       "1480  254.698898  180.479706  249.408005  179.833176  261.246094  204.217148   \n",
       "1481  253.565445  177.212082  253.720291  178.292694  263.932465  202.223892   \n",
       "\n",
       "          kp16_x      kp16_y  action_class  \n",
       "0     478.328369  440.453247             0  \n",
       "1     473.916595  442.841217             0  \n",
       "2     478.228882  438.963867             0  \n",
       "3     474.512299  441.921783             0  \n",
       "4     487.770660  414.044739             0  \n",
       "...          ...         ...           ...  \n",
       "1477  304.511932  220.732727             2  \n",
       "1478  303.347900  220.787003             2  \n",
       "1479  252.283371  204.398911             2  \n",
       "1480  259.570312  204.109390             2  \n",
       "1481  263.420746  202.218918             2  \n",
       "\n",
       "[1482 rows x 35 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임 확인\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1736817010142,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "vbBXiHUyyavB"
   },
   "outputs": [],
   "source": [
    "# X, y 분리\n",
    "X = df.iloc[:, :-1].values # 키포인트\n",
    "y = df.iloc[:, -1].values # 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\action_recognition\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:87: RuntimeWarning: invalid value encountered in cast\n",
      "  x = np.array(x, dtype=\"int64\")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -9223372036854775808 is out of bounds for axis 1 with size 221",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 레이블 원-핫 인코딩\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\action_recognition\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:99\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(x, num_classes)\u001b[0m\n\u001b[0;32m     97\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     98\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n\u001b[1;32m---> 99\u001b[0m \u001b[43mcategorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    100\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[0;32m    101\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: index -9223372036854775808 is out of bounds for axis 1 with size 221"
     ]
    }
   ],
   "source": [
    "# 레이블 원-핫 인코딩\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1736817034025,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "lX9vCsAb1ZHn"
   },
   "outputs": [],
   "source": [
    "# 데이터 시퀀스 길이 지정\n",
    "seq_length = 3  # 시퀀스 길이\n",
    "\n",
    "# 데이터를 시퀀스 형태로 변환\n",
    "X_seq, y_seq = reshape_to_sequences(X, y, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1736817040984,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "0aLSjL8nyavB"
   },
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1736817068598,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "ddZ5tAf5yavC",
    "outputId": "54f66270-21d4-45c9-ee91-9470d50a51db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\action_recognition\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(seq_length, X_train.shape[2]), return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(y_train.shape[1], activation=\"softmax\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14658,
     "status": "ok",
     "timestamp": 1736817088559,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "DYMwh9xXyavC",
    "outputId": "e7df7203-1de3-450a-c62a-ce8337c8c321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.3852 - loss: 1.4652 - val_accuracy: 0.4595 - val_loss: 1.2855\n",
      "Epoch 2/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5145 - loss: 1.2233 - val_accuracy: 0.5777 - val_loss: 1.0715\n",
      "Epoch 3/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5668 - loss: 1.0612 - val_accuracy: 0.5912 - val_loss: 1.0094\n",
      "Epoch 4/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6002 - loss: 1.0318 - val_accuracy: 0.5912 - val_loss: 1.0118\n",
      "Epoch 5/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6170 - loss: 0.9676 - val_accuracy: 0.6318 - val_loss: 0.9027\n",
      "Epoch 6/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6317 - loss: 0.9331 - val_accuracy: 0.6385 - val_loss: 0.9206\n",
      "Epoch 7/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6214 - loss: 0.9285 - val_accuracy: 0.6318 - val_loss: 0.9140\n",
      "Epoch 8/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6632 - loss: 0.8487 - val_accuracy: 0.6791 - val_loss: 0.8368\n",
      "Epoch 9/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6633 - loss: 0.8250 - val_accuracy: 0.6858 - val_loss: 0.8175\n",
      "Epoch 10/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6455 - loss: 0.8361 - val_accuracy: 0.6689 - val_loss: 0.8525\n",
      "Epoch 11/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6419 - loss: 0.8686 - val_accuracy: 0.6723 - val_loss: 0.8130\n",
      "Epoch 12/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6793 - loss: 0.8079 - val_accuracy: 0.6318 - val_loss: 0.9130\n",
      "Epoch 13/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6386 - loss: 0.8608 - val_accuracy: 0.6622 - val_loss: 0.8258\n",
      "Epoch 14/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6643 - loss: 0.8086 - val_accuracy: 0.6622 - val_loss: 0.8595\n",
      "Epoch 15/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6479 - loss: 0.8638 - val_accuracy: 0.6486 - val_loss: 0.8104\n",
      "Epoch 16/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6798 - loss: 0.7860 - val_accuracy: 0.6588 - val_loss: 0.8592\n",
      "Epoch 17/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6533 - loss: 0.8251 - val_accuracy: 0.7027 - val_loss: 0.7777\n",
      "Epoch 18/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6820 - loss: 0.7710 - val_accuracy: 0.7061 - val_loss: 0.7860\n",
      "Epoch 19/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7160 - loss: 0.7445 - val_accuracy: 0.7061 - val_loss: 0.7101\n",
      "Epoch 20/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7137 - loss: 0.7299 - val_accuracy: 0.6689 - val_loss: 0.7500\n",
      "Epoch 21/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6892 - loss: 0.7468 - val_accuracy: 0.6791 - val_loss: 0.7751\n",
      "Epoch 22/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7198 - loss: 0.7087 - val_accuracy: 0.7061 - val_loss: 0.7037\n",
      "Epoch 23/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7264 - loss: 0.6895 - val_accuracy: 0.6014 - val_loss: 0.8940\n",
      "Epoch 24/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6751 - loss: 0.7625 - val_accuracy: 0.5304 - val_loss: 0.9913\n",
      "Epoch 25/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6664 - loss: 0.7930 - val_accuracy: 0.7264 - val_loss: 0.7253\n",
      "Epoch 26/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7488 - loss: 0.6807 - val_accuracy: 0.7128 - val_loss: 0.7301\n",
      "Epoch 27/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7443 - loss: 0.6731 - val_accuracy: 0.6622 - val_loss: 0.7668\n",
      "Epoch 28/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7334 - loss: 0.6713 - val_accuracy: 0.7264 - val_loss: 0.7390\n",
      "Epoch 29/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7035 - loss: 0.7415 - val_accuracy: 0.7568 - val_loss: 0.6628\n",
      "Epoch 30/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7468 - loss: 0.6206 - val_accuracy: 0.6757 - val_loss: 0.6951\n",
      "Epoch 31/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6906 - loss: 0.7166 - val_accuracy: 0.6655 - val_loss: 0.8346\n",
      "Epoch 32/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7264 - loss: 0.7113 - val_accuracy: 0.6791 - val_loss: 0.8087\n",
      "Epoch 33/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6948 - loss: 0.7714 - val_accuracy: 0.7196 - val_loss: 0.6992\n",
      "Epoch 34/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7721 - loss: 0.6294 - val_accuracy: 0.7736 - val_loss: 0.6289\n",
      "Epoch 35/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7631 - loss: 0.6251 - val_accuracy: 0.7095 - val_loss: 0.6883\n",
      "Epoch 36/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7429 - loss: 0.6933 - val_accuracy: 0.7466 - val_loss: 0.7035\n",
      "Epoch 37/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7280 - loss: 0.6471 - val_accuracy: 0.7230 - val_loss: 0.6952\n",
      "Epoch 38/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - loss: 0.5845 - val_accuracy: 0.7095 - val_loss: 0.7430\n",
      "Epoch 39/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7081 - loss: 0.7037 - val_accuracy: 0.6993 - val_loss: 0.7650\n",
      "Epoch 40/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7141 - loss: 0.7020 - val_accuracy: 0.6554 - val_loss: 0.7797\n",
      "Epoch 41/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7128 - loss: 0.6838 - val_accuracy: 0.7061 - val_loss: 0.7178\n",
      "Epoch 42/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7537 - loss: 0.6173 - val_accuracy: 0.7162 - val_loss: 0.7333\n",
      "Epoch 43/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7674 - loss: 0.5873 - val_accuracy: 0.7331 - val_loss: 0.6909\n",
      "Epoch 44/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7695 - loss: 0.5894 - val_accuracy: 0.6757 - val_loss: 0.7457\n",
      "Epoch 45/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7084 - loss: 0.6806 - val_accuracy: 0.6588 - val_loss: 0.7652\n",
      "Epoch 46/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7307 - loss: 0.6652 - val_accuracy: 0.6723 - val_loss: 0.8193\n",
      "Epoch 47/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7204 - loss: 0.6838 - val_accuracy: 0.7500 - val_loss: 0.7350\n",
      "Epoch 48/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7387 - loss: 0.6120 - val_accuracy: 0.7365 - val_loss: 0.6790\n",
      "Epoch 49/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7319 - loss: 0.6153 - val_accuracy: 0.7568 - val_loss: 0.6111\n",
      "Epoch 50/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7654 - loss: 0.5821 - val_accuracy: 0.7297 - val_loss: 0.6861\n",
      "Epoch 51/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7579 - loss: 0.5907 - val_accuracy: 0.7534 - val_loss: 0.6685\n",
      "Epoch 52/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7570 - loss: 0.6182 - val_accuracy: 0.7297 - val_loss: 0.6141\n",
      "Epoch 53/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7673 - loss: 0.5970 - val_accuracy: 0.7297 - val_loss: 0.6537\n",
      "Epoch 54/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7742 - loss: 0.5957 - val_accuracy: 0.7297 - val_loss: 0.6871\n",
      "Epoch 55/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7604 - loss: 0.5681 - val_accuracy: 0.7196 - val_loss: 0.6570\n",
      "Epoch 56/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7697 - loss: 0.5666 - val_accuracy: 0.7331 - val_loss: 0.6422\n",
      "Epoch 57/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7510 - loss: 0.6279 - val_accuracy: 0.7500 - val_loss: 0.7102\n",
      "Epoch 58/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7548 - loss: 0.6285 - val_accuracy: 0.7601 - val_loss: 0.6819\n",
      "Epoch 59/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.5371 - val_accuracy: 0.7804 - val_loss: 0.6232\n",
      "Epoch 60/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7686 - loss: 0.5807 - val_accuracy: 0.7500 - val_loss: 0.6038\n",
      "Epoch 61/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8056 - loss: 0.4973 - val_accuracy: 0.7804 - val_loss: 0.5909\n",
      "Epoch 62/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8013 - loss: 0.4729 - val_accuracy: 0.7804 - val_loss: 0.5892\n",
      "Epoch 63/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7783 - loss: 0.5620 - val_accuracy: 0.8176 - val_loss: 0.5303\n",
      "Epoch 64/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8267 - loss: 0.4655 - val_accuracy: 0.7939 - val_loss: 0.5540\n",
      "Epoch 65/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7980 - loss: 0.5109 - val_accuracy: 0.7770 - val_loss: 0.5679\n",
      "Epoch 66/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8318 - loss: 0.4254 - val_accuracy: 0.7534 - val_loss: 0.6201\n",
      "Epoch 67/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7997 - loss: 0.4858 - val_accuracy: 0.8108 - val_loss: 0.5277\n",
      "Epoch 68/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8054 - loss: 0.4750 - val_accuracy: 0.7331 - val_loss: 0.6781\n",
      "Epoch 69/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7563 - loss: 0.6438 - val_accuracy: 0.7466 - val_loss: 0.6304\n",
      "Epoch 70/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8140 - loss: 0.5112 - val_accuracy: 0.7500 - val_loss: 0.6825\n",
      "Epoch 71/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7917 - loss: 0.5228 - val_accuracy: 0.7669 - val_loss: 0.5770\n",
      "Epoch 72/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7879 - loss: 0.5337 - val_accuracy: 0.6926 - val_loss: 0.7520\n",
      "Epoch 73/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7625 - loss: 0.6207 - val_accuracy: 0.7162 - val_loss: 0.7056\n",
      "Epoch 74/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7120 - loss: 0.7042 - val_accuracy: 0.6486 - val_loss: 0.7954\n",
      "Epoch 75/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7507 - loss: 0.6083 - val_accuracy: 0.7568 - val_loss: 0.6615\n",
      "Epoch 76/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8033 - loss: 0.5277 - val_accuracy: 0.7838 - val_loss: 0.6130\n",
      "Epoch 77/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7829 - loss: 0.5236 - val_accuracy: 0.7500 - val_loss: 0.6277\n",
      "Epoch 78/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7919 - loss: 0.5551 - val_accuracy: 0.6993 - val_loss: 0.6898\n",
      "Epoch 79/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8072 - loss: 0.5077 - val_accuracy: 0.7162 - val_loss: 0.6235\n",
      "Epoch 80/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7739 - loss: 0.5352 - val_accuracy: 0.7264 - val_loss: 0.6642\n",
      "Epoch 81/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7878 - loss: 0.5210 - val_accuracy: 0.7297 - val_loss: 0.7169\n",
      "Epoch 82/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7651 - loss: 0.5648 - val_accuracy: 0.6757 - val_loss: 0.7632\n",
      "Epoch 83/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.5610 - val_accuracy: 0.7601 - val_loss: 0.6276\n",
      "Epoch 84/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7908 - loss: 0.5412 - val_accuracy: 0.7027 - val_loss: 0.7168\n",
      "Epoch 85/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7718 - loss: 0.5710 - val_accuracy: 0.7432 - val_loss: 0.6672\n",
      "Epoch 86/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7927 - loss: 0.5175 - val_accuracy: 0.7095 - val_loss: 0.6566\n",
      "Epoch 87/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7919 - loss: 0.5005 - val_accuracy: 0.7399 - val_loss: 0.6715\n",
      "Epoch 88/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7793 - loss: 0.5027 - val_accuracy: 0.7568 - val_loss: 0.6312\n",
      "Epoch 89/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8017 - loss: 0.5111 - val_accuracy: 0.7432 - val_loss: 0.6745\n",
      "Epoch 90/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7766 - loss: 0.5322 - val_accuracy: 0.7432 - val_loss: 0.6629\n",
      "Epoch 91/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7744 - loss: 0.5450 - val_accuracy: 0.7264 - val_loss: 0.6851\n",
      "Epoch 92/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8007 - loss: 0.4788 - val_accuracy: 0.7703 - val_loss: 0.6050\n",
      "Epoch 93/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7799 - loss: 0.5005 - val_accuracy: 0.7601 - val_loss: 0.6177\n",
      "Epoch 94/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8218 - loss: 0.4400 - val_accuracy: 0.7568 - val_loss: 0.6270\n",
      "Epoch 95/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7830 - loss: 0.5304 - val_accuracy: 0.7601 - val_loss: 0.6102\n",
      "Epoch 96/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8103 - loss: 0.5174 - val_accuracy: 0.7635 - val_loss: 0.5964\n",
      "Epoch 97/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8044 - loss: 0.4975 - val_accuracy: 0.7264 - val_loss: 0.6888\n",
      "Epoch 98/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7575 - loss: 0.5879 - val_accuracy: 0.7365 - val_loss: 0.6403\n",
      "Epoch 99/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7387 - loss: 0.6382 - val_accuracy: 0.7297 - val_loss: 0.7276\n",
      "Epoch 100/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7352 - loss: 0.6439 - val_accuracy: 0.7635 - val_loss: 0.5991\n",
      "Epoch 101/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7906 - loss: 0.5335 - val_accuracy: 0.7568 - val_loss: 0.6347\n",
      "Epoch 102/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7816 - loss: 0.5257 - val_accuracy: 0.7399 - val_loss: 0.6206\n",
      "Epoch 103/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 0.5340 - val_accuracy: 0.7432 - val_loss: 0.6530\n",
      "Epoch 104/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7728 - loss: 0.5185 - val_accuracy: 0.6926 - val_loss: 0.7026\n",
      "Epoch 105/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7915 - loss: 0.5172 - val_accuracy: 0.7534 - val_loss: 0.6181\n",
      "Epoch 106/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7959 - loss: 0.5209 - val_accuracy: 0.7399 - val_loss: 0.6232\n",
      "Epoch 107/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8205 - loss: 0.4645 - val_accuracy: 0.7804 - val_loss: 0.5742\n",
      "Epoch 108/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8014 - loss: 0.4905 - val_accuracy: 0.6993 - val_loss: 0.9099\n",
      "Epoch 109/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7431 - loss: 0.6774 - val_accuracy: 0.7264 - val_loss: 0.6255\n",
      "Epoch 110/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7960 - loss: 0.4722 - val_accuracy: 0.7703 - val_loss: 0.5597\n",
      "Epoch 111/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8254 - loss: 0.4615 - val_accuracy: 0.7331 - val_loss: 0.6079\n",
      "Epoch 112/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7934 - loss: 0.5291 - val_accuracy: 0.7128 - val_loss: 0.6391\n",
      "Epoch 113/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8020 - loss: 0.4489 - val_accuracy: 0.7568 - val_loss: 0.6000\n",
      "Epoch 114/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 0.4457 - val_accuracy: 0.7669 - val_loss: 0.5857\n",
      "Epoch 115/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8302 - loss: 0.4340 - val_accuracy: 0.7230 - val_loss: 0.6621\n",
      "Epoch 116/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7586 - loss: 0.5628 - val_accuracy: 0.7601 - val_loss: 0.6048\n",
      "Epoch 117/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7709 - loss: 0.5186 - val_accuracy: 0.7804 - val_loss: 0.5644\n",
      "Epoch 118/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8275 - loss: 0.4647 - val_accuracy: 0.7399 - val_loss: 0.6256\n",
      "Epoch 119/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7910 - loss: 0.5365 - val_accuracy: 0.6655 - val_loss: 0.7503\n",
      "Epoch 120/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7439 - loss: 0.6760 - val_accuracy: 0.7027 - val_loss: 0.6879\n",
      "Epoch 121/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7951 - loss: 0.4900 - val_accuracy: 0.7601 - val_loss: 0.5641\n",
      "Epoch 122/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7826 - loss: 0.5331 - val_accuracy: 0.7432 - val_loss: 0.6076\n",
      "Epoch 123/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8044 - loss: 0.4834 - val_accuracy: 0.7500 - val_loss: 0.6402\n",
      "Epoch 124/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8251 - loss: 0.4659 - val_accuracy: 0.7703 - val_loss: 0.5468\n",
      "Epoch 125/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8241 - loss: 0.4041 - val_accuracy: 0.7838 - val_loss: 0.5478\n",
      "Epoch 126/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8425 - loss: 0.4479 - val_accuracy: 0.7365 - val_loss: 0.6074\n",
      "Epoch 127/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 0.4604 - val_accuracy: 0.7601 - val_loss: 0.5983\n",
      "Epoch 128/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8058 - loss: 0.4806 - val_accuracy: 0.7770 - val_loss: 0.5469\n",
      "Epoch 129/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8320 - loss: 0.4243 - val_accuracy: 0.7568 - val_loss: 0.5711\n",
      "Epoch 130/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8460 - loss: 0.4056 - val_accuracy: 0.7804 - val_loss: 0.5143\n",
      "Epoch 131/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8623 - loss: 0.3592 - val_accuracy: 0.7804 - val_loss: 0.5371\n",
      "Epoch 132/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 0.4056 - val_accuracy: 0.7534 - val_loss: 0.5791\n",
      "Epoch 133/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.4095 - val_accuracy: 0.7804 - val_loss: 0.5497\n",
      "Epoch 134/300\n",
      "\u001b[1m36/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 0.3957"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=300, batch_size=32, callbacks=es)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\action_recognition\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\action_recognition\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:406\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    386\u001b[0m             x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    387\u001b[0m             y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    394\u001b[0m         )\n\u001b[0;32m    395\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    396\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    397\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m         _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    404\u001b[0m     )\n\u001b[0;32m    405\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m \u001b[43mval_logs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m     }\n\u001b[0;32m    408\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m    410\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_end(epoch, epoch_logs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # 모델 컴파일 및 학습\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "es = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3, mode = 'auto')\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=300, batch_size=32, callbacks=es)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=300, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1736498705187,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "OCB8taP2yavC",
    "outputId": "c18c1b7b-de05-4ffb-a0c5-14ab56503bfa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "output_model = './Model/LSTM.h5'\n",
    "model.save(output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1736817098363,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "zWxhnnUcOYPs",
    "outputId": "de5babdf-b6f8-47a8-ec48-07c37aecb7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 정확도: 76.87%\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델 평가\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"검증 데이터 정확도: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "action_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
