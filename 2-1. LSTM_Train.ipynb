{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 6344,
     "status": "ok",
     "timestamp": 1736816975834,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "RcPpb0t6yau8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 948,
     "status": "ok",
     "timestamp": 1736816979723,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "F56DvJR2yavA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# LSTM_Data 폴더의 모든 CSV 파일 병합\n",
    "def load_csvs_to_dataframe(folder_path):\n",
    "    \"\"\"\n",
    "    폴더 및 하위 폴더에 있는 모든 CSV 파일을 로드하여 하나의 DataFrame으로 병합합니다.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): CSV 파일이 저장된 폴더 경로.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 병합된 DataFrame.\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "\n",
    "    # 하위 폴더까지 탐색\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                csv_path = os.path.join(root, file)\n",
    "\n",
    "                # 클래스 번호 추출 (상위 폴더 이름에서)\n",
    "                class_folder = os.path.basename(os.path.dirname(csv_path))\n",
    "                try:\n",
    "                    action_class = int(class_folder)\n",
    "                except ValueError:\n",
    "                    print(f\"경고: {csv_path}의 상위 폴더 '{class_folder}'는 유효한 클래스가 아닙니다. 건너뜁니다.\")\n",
    "                    continue\n",
    "\n",
    "                # CSV 불러오기 및 클래스 열 추가\n",
    "                df = pd.read_csv(csv_path)\n",
    "                if 'action_class' not in df.columns:\n",
    "                    df['action_class'] = action_class  # 없으면 클래스 열 추가\n",
    "\n",
    "                csv_files.append(df)\n",
    "\n",
    "    # 모든 CSV 파일 병합\n",
    "    if csv_files:\n",
    "        combined_df = pd.concat(csv_files, ignore_index=True)\n",
    "        print(f\"총 {len(csv_files)}개의 CSV 파일을 병합했습니다. 데이터 크기: {combined_df.shape}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"병합할 CSV 파일이 없습니다.\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736816981402,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "XCctZO0JEt3_"
   },
   "outputs": [],
   "source": [
    "# 데이터 시퀀스별로 변환\n",
    "def reshape_to_sequences(data, labels, seq_length):\n",
    "    \"\"\"\n",
    "    데이터를 시퀀스 형태로 변환합니다.\n",
    "    Args:\n",
    "        data (np.array): 키포인트 데이터.\n",
    "        labels (np.array): 레이블 데이터.\n",
    "        seq_length (int): 시퀀스 길이.\n",
    "    Returns:\n",
    "        np.array, np.array: 시퀀스화된 입력 데이터와 레이블.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        sequence_labels.append(labels[i + seq_length - 1])  # 시퀀스의 마지막 레이블 사용\n",
    "    return np.array(sequences), np.array(sequence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7399,
     "status": "ok",
     "timestamp": 1736816993226,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "v9lYaWtICsyN",
    "outputId": "5674cacd-ed53-49a6-8117-5ae8b539a54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 49개의 CSV 파일을 병합했습니다. 데이터 크기: (1470, 35)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 및 병합\n",
    "folder_path = './LSTM_Data'  # 데이터 폴더 경로\n",
    "df = load_csvs_to_dataframe(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1736817010142,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "vbBXiHUyyavB"
   },
   "outputs": [],
   "source": [
    "# X, y 분리\n",
    "X = df.iloc[:, :-1].values # 키포인트\n",
    "y = df.iloc[:, -1].values # 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1736817028160,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "ZtKuIP-KyavB"
   },
   "outputs": [],
   "source": [
    "# 레이블 원-핫 인코딩\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1736817034025,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "lX9vCsAb1ZHn"
   },
   "outputs": [],
   "source": [
    "# 데이터 시퀀스 길이 지정\n",
    "seq_length = 3  # 시퀀스 길이\n",
    "\n",
    "# 데이터를 시퀀스 형태로 변환\n",
    "X_seq, y_seq = reshape_to_sequences(X, y, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1736817040984,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "0aLSjL8nyavB"
   },
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1736817068598,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "ddZ5tAf5yavC",
    "outputId": "54f66270-21d4-45c9-ee91-9470d50a51db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(seq_length, X_train.shape[2]), return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(y_train.shape[1], activation=\"softmax\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14658,
     "status": "ok",
     "timestamp": 1736817088559,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "DYMwh9xXyavC",
    "outputId": "e7df7203-1de3-450a-c62a-ce8337c8c321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6286 - loss: 0.8671 - val_accuracy: 0.6327 - val_loss: 0.8417\n",
      "Epoch 2/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6552 - loss: 0.7993 - val_accuracy: 0.6599 - val_loss: 0.8128\n",
      "Epoch 3/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6958 - loss: 0.7733 - val_accuracy: 0.6122 - val_loss: 0.8309\n",
      "Epoch 4/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6643 - loss: 0.7449 - val_accuracy: 0.6905 - val_loss: 0.7537\n",
      "Epoch 5/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6806 - loss: 0.7241 - val_accuracy: 0.6939 - val_loss: 0.7885\n",
      "Epoch 6/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.6632 - val_accuracy: 0.7075 - val_loss: 0.7766\n",
      "Epoch 7/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7101 - loss: 0.7030 - val_accuracy: 0.7109 - val_loss: 0.7355\n",
      "Epoch 8/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.6270 - val_accuracy: 0.6395 - val_loss: 0.7890\n",
      "Epoch 9/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7167 - loss: 0.6605 - val_accuracy: 0.6633 - val_loss: 0.7879\n",
      "Epoch 10/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7002 - loss: 0.6753 - val_accuracy: 0.6837 - val_loss: 0.7306\n",
      "Epoch 11/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6858 - loss: 0.7087 - val_accuracy: 0.6259 - val_loss: 0.7865\n",
      "Epoch 12/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7177 - loss: 0.6683 - val_accuracy: 0.6837 - val_loss: 0.6550\n",
      "Epoch 13/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7564 - loss: 0.5668 - val_accuracy: 0.6871 - val_loss: 0.8049\n",
      "Epoch 14/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7446 - loss: 0.5840 - val_accuracy: 0.6871 - val_loss: 0.7013\n",
      "Epoch 15/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7434 - loss: 0.6148 - val_accuracy: 0.6327 - val_loss: 0.8043\n",
      "Epoch 16/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7294 - loss: 0.6545 - val_accuracy: 0.6837 - val_loss: 0.7465\n",
      "Epoch 17/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7292 - loss: 0.6343 - val_accuracy: 0.6939 - val_loss: 0.6963\n",
      "Epoch 18/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7316 - loss: 0.6531 - val_accuracy: 0.7245 - val_loss: 0.6649\n",
      "Epoch 19/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7870 - loss: 0.5356 - val_accuracy: 0.7245 - val_loss: 0.6782\n",
      "Epoch 20/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.5762 - val_accuracy: 0.6871 - val_loss: 0.7941\n",
      "Epoch 21/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7071 - loss: 0.6487 - val_accuracy: 0.7279 - val_loss: 0.6644\n",
      "Epoch 22/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7765 - loss: 0.5584 - val_accuracy: 0.7551 - val_loss: 0.6378\n",
      "Epoch 23/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7705 - loss: 0.5734 - val_accuracy: 0.7279 - val_loss: 0.7295\n",
      "Epoch 24/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7401 - loss: 0.6280 - val_accuracy: 0.7041 - val_loss: 0.7124\n",
      "Epoch 25/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7322 - loss: 0.6217 - val_accuracy: 0.7483 - val_loss: 0.6467\n",
      "Epoch 26/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.5622 - val_accuracy: 0.6565 - val_loss: 0.7549\n",
      "Epoch 27/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6826 - loss: 0.7512 - val_accuracy: 0.6769 - val_loss: 0.7042\n",
      "Epoch 28/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7413 - loss: 0.5673 - val_accuracy: 0.7313 - val_loss: 0.6282\n",
      "Epoch 29/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.5445 - val_accuracy: 0.7313 - val_loss: 0.7422\n",
      "Epoch 30/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7496 - loss: 0.5373 - val_accuracy: 0.7415 - val_loss: 0.5690\n",
      "Epoch 31/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7734 - loss: 0.5194 - val_accuracy: 0.7789 - val_loss: 0.5775\n",
      "Epoch 32/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5546 - val_accuracy: 0.7483 - val_loss: 0.5962\n",
      "Epoch 33/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.5150 - val_accuracy: 0.7415 - val_loss: 0.6392\n",
      "Epoch 34/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.5206 - val_accuracy: 0.7721 - val_loss: 0.6267\n",
      "Epoch 35/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.5213 - val_accuracy: 0.7449 - val_loss: 0.6538\n",
      "Epoch 36/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7785 - loss: 0.5379 - val_accuracy: 0.7619 - val_loss: 0.5981\n",
      "Epoch 37/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4996 - val_accuracy: 0.7619 - val_loss: 0.5458\n",
      "Epoch 38/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7801 - loss: 0.5729 - val_accuracy: 0.7075 - val_loss: 0.7305\n",
      "Epoch 39/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.5696 - val_accuracy: 0.8129 - val_loss: 0.5329\n",
      "Epoch 40/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.4688 - val_accuracy: 0.7313 - val_loss: 0.5387\n",
      "Epoch 41/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.5125 - val_accuracy: 0.7619 - val_loss: 0.6306\n",
      "Epoch 42/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.5216 - val_accuracy: 0.7449 - val_loss: 0.5657\n",
      "Epoch 43/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7939 - loss: 0.4639 - val_accuracy: 0.7653 - val_loss: 0.5696\n",
      "Epoch 44/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4539 - val_accuracy: 0.7721 - val_loss: 0.6073\n",
      "Epoch 45/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4994 - val_accuracy: 0.7109 - val_loss: 0.6919\n",
      "Epoch 46/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.4519 - val_accuracy: 0.7993 - val_loss: 0.5411\n",
      "Epoch 47/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.4450 - val_accuracy: 0.7551 - val_loss: 0.5489\n",
      "Epoch 48/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.5164 - val_accuracy: 0.7891 - val_loss: 0.5259\n",
      "Epoch 49/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7931 - loss: 0.4774 - val_accuracy: 0.7789 - val_loss: 0.5427\n",
      "Epoch 50/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4607 - val_accuracy: 0.8197 - val_loss: 0.5692\n",
      "Epoch 51/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8049 - loss: 0.5116 - val_accuracy: 0.7823 - val_loss: 0.5869\n",
      "Epoch 52/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4999 - val_accuracy: 0.7211 - val_loss: 0.6990\n",
      "Epoch 53/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.5229 - val_accuracy: 0.7449 - val_loss: 0.6601\n",
      "Epoch 54/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7830 - loss: 0.5335 - val_accuracy: 0.7517 - val_loss: 0.5961\n",
      "Epoch 55/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.5889 - val_accuracy: 0.7313 - val_loss: 0.7236\n",
      "Epoch 56/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.5788 - val_accuracy: 0.6361 - val_loss: 0.8619\n",
      "Epoch 57/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7455 - loss: 0.6173 - val_accuracy: 0.7619 - val_loss: 0.6047\n",
      "Epoch 58/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.5206 - val_accuracy: 0.7619 - val_loss: 0.6557\n",
      "Epoch 59/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7731 - loss: 0.5537 - val_accuracy: 0.7551 - val_loss: 0.6756\n",
      "Epoch 60/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7426 - loss: 0.5714 - val_accuracy: 0.7007 - val_loss: 0.7244\n",
      "Epoch 61/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7627 - loss: 0.5596 - val_accuracy: 0.8027 - val_loss: 0.5431\n",
      "Epoch 62/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7816 - loss: 0.5045 - val_accuracy: 0.7313 - val_loss: 0.6548\n",
      "Epoch 63/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4675 - val_accuracy: 0.7415 - val_loss: 0.5911\n",
      "Epoch 64/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.4867 - val_accuracy: 0.7653 - val_loss: 0.5491\n",
      "Epoch 65/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.4792 - val_accuracy: 0.7619 - val_loss: 0.5778\n",
      "Epoch 66/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4764 - val_accuracy: 0.7619 - val_loss: 0.5649\n",
      "Epoch 67/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4827 - val_accuracy: 0.7687 - val_loss: 0.5292\n",
      "Epoch 68/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8207 - loss: 0.4114 - val_accuracy: 0.8129 - val_loss: 0.5156\n",
      "Epoch 69/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8350 - loss: 0.4248 - val_accuracy: 0.6939 - val_loss: 0.8366\n",
      "Epoch 70/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.6413 - val_accuracy: 0.7517 - val_loss: 0.6031\n",
      "Epoch 71/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.6956 - val_accuracy: 0.7415 - val_loss: 0.6375\n",
      "Epoch 72/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7562 - loss: 0.5663 - val_accuracy: 0.7415 - val_loss: 0.6808\n",
      "Epoch 73/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7725 - loss: 0.5199 - val_accuracy: 0.7551 - val_loss: 0.5698\n",
      "Epoch 74/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.4512 - val_accuracy: 0.7449 - val_loss: 0.5785\n",
      "Epoch 75/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.4520 - val_accuracy: 0.7585 - val_loss: 0.5828\n",
      "Epoch 76/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8095 - loss: 0.4328 - val_accuracy: 0.7687 - val_loss: 0.5480\n",
      "Epoch 77/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.3846 - val_accuracy: 0.7857 - val_loss: 0.5708\n",
      "Epoch 78/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4758 - val_accuracy: 0.7687 - val_loss: 0.5492\n",
      "Epoch 79/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8260 - loss: 0.4501 - val_accuracy: 0.7823 - val_loss: 0.5756\n",
      "Epoch 80/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.4457 - val_accuracy: 0.6905 - val_loss: 0.6793\n",
      "Epoch 81/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7614 - loss: 0.5622 - val_accuracy: 0.7279 - val_loss: 0.5705\n",
      "Epoch 82/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.4133 - val_accuracy: 0.7619 - val_loss: 0.5373\n",
      "Epoch 83/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 0.4672 - val_accuracy: 0.7755 - val_loss: 0.5680\n",
      "Epoch 84/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 0.4460 - val_accuracy: 0.7347 - val_loss: 0.6589\n",
      "Epoch 85/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.4453 - val_accuracy: 0.7823 - val_loss: 0.5594\n",
      "Epoch 86/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.4361 - val_accuracy: 0.7823 - val_loss: 0.5553\n",
      "Epoch 87/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.4205 - val_accuracy: 0.7823 - val_loss: 0.5524\n",
      "Epoch 88/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 0.4146 - val_accuracy: 0.7619 - val_loss: 0.6007\n",
      "Epoch 89/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7960 - loss: 0.4413 - val_accuracy: 0.7891 - val_loss: 0.5632\n",
      "Epoch 90/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.5455 - val_accuracy: 0.6769 - val_loss: 0.8858\n",
      "Epoch 91/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7571 - loss: 0.5552 - val_accuracy: 0.7551 - val_loss: 0.6266\n",
      "Epoch 92/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8302 - loss: 0.4120 - val_accuracy: 0.8197 - val_loss: 0.4943\n",
      "Epoch 93/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8681 - loss: 0.3450 - val_accuracy: 0.8163 - val_loss: 0.4923\n",
      "Epoch 94/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8282 - loss: 0.3958 - val_accuracy: 0.7959 - val_loss: 0.6049\n",
      "Epoch 95/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 0.4011 - val_accuracy: 0.7789 - val_loss: 0.5410\n",
      "Epoch 96/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8460 - loss: 0.3827 - val_accuracy: 0.8095 - val_loss: 0.5372\n",
      "Epoch 97/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8387 - loss: 0.3789 - val_accuracy: 0.8197 - val_loss: 0.4629\n",
      "Epoch 98/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.4226 - val_accuracy: 0.7517 - val_loss: 0.5445\n",
      "Epoch 99/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.5823 - val_accuracy: 0.7415 - val_loss: 0.7261\n",
      "Epoch 100/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7436 - loss: 0.6218 - val_accuracy: 0.7109 - val_loss: 0.6602\n",
      "Epoch 101/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.3928 - val_accuracy: 0.7687 - val_loss: 0.6032\n",
      "Epoch 102/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8579 - loss: 0.3806 - val_accuracy: 0.8231 - val_loss: 0.4852\n",
      "Epoch 103/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.3649 - val_accuracy: 0.7823 - val_loss: 0.5410\n",
      "Epoch 104/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.3715 - val_accuracy: 0.7925 - val_loss: 0.5422\n",
      "Epoch 105/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.3381 - val_accuracy: 0.7721 - val_loss: 0.5032\n",
      "Epoch 106/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 0.3349 - val_accuracy: 0.8197 - val_loss: 0.5009\n",
      "Epoch 107/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8522 - loss: 0.3447 - val_accuracy: 0.8197 - val_loss: 0.5683\n",
      "Epoch 108/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 0.3844 - val_accuracy: 0.7755 - val_loss: 0.6392\n",
      "Epoch 109/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.3997 - val_accuracy: 0.8197 - val_loss: 0.5186\n",
      "Epoch 110/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8448 - loss: 0.3648 - val_accuracy: 0.8231 - val_loss: 0.5023\n",
      "Epoch 111/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8762 - loss: 0.3067 - val_accuracy: 0.7415 - val_loss: 0.6503\n",
      "Epoch 112/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - loss: 0.4006 - val_accuracy: 0.7143 - val_loss: 0.6907\n",
      "Epoch 113/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8242 - loss: 0.5024 - val_accuracy: 0.7347 - val_loss: 0.6511\n",
      "Epoch 114/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.4613 - val_accuracy: 0.8027 - val_loss: 0.5388\n",
      "Epoch 115/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8256 - loss: 0.4186 - val_accuracy: 0.6939 - val_loss: 0.8339\n",
      "Epoch 116/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7649 - loss: 0.5727 - val_accuracy: 0.7381 - val_loss: 0.5943\n",
      "Epoch 117/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.4617 - val_accuracy: 0.8061 - val_loss: 0.4882\n",
      "Epoch 118/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8209 - loss: 0.4365 - val_accuracy: 0.7721 - val_loss: 0.6256\n",
      "Epoch 119/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.4853 - val_accuracy: 0.7585 - val_loss: 0.6156\n",
      "Epoch 120/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8078 - loss: 0.4447 - val_accuracy: 0.7347 - val_loss: 0.6223\n",
      "Epoch 121/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4479 - val_accuracy: 0.8333 - val_loss: 0.4578\n",
      "Epoch 122/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8638 - loss: 0.3367 - val_accuracy: 0.8265 - val_loss: 0.4719\n",
      "Epoch 123/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8445 - loss: 0.3883 - val_accuracy: 0.7415 - val_loss: 0.6765\n",
      "Epoch 124/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8211 - loss: 0.4482 - val_accuracy: 0.7721 - val_loss: 0.6029\n",
      "Epoch 125/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.4079 - val_accuracy: 0.7585 - val_loss: 0.5709\n",
      "Epoch 126/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.3788 - val_accuracy: 0.8163 - val_loss: 0.4815\n",
      "Epoch 127/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.3869 - val_accuracy: 0.7449 - val_loss: 0.5871\n",
      "Epoch 128/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.4138 - val_accuracy: 0.7891 - val_loss: 0.5575\n",
      "Epoch 129/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - loss: 0.3944 - val_accuracy: 0.7109 - val_loss: 0.6703\n",
      "Epoch 130/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.4313 - val_accuracy: 0.8367 - val_loss: 0.4464\n",
      "Epoch 131/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8348 - loss: 0.4018 - val_accuracy: 0.7551 - val_loss: 0.5982\n",
      "Epoch 132/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 0.3802 - val_accuracy: 0.8469 - val_loss: 0.3979\n",
      "Epoch 133/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8652 - loss: 0.3309 - val_accuracy: 0.8163 - val_loss: 0.4506\n",
      "Epoch 134/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8719 - loss: 0.3350 - val_accuracy: 0.8231 - val_loss: 0.4682\n",
      "Epoch 135/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8773 - loss: 0.2971 - val_accuracy: 0.7891 - val_loss: 0.6154\n",
      "Epoch 136/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4576 - val_accuracy: 0.7517 - val_loss: 0.6148\n",
      "Epoch 137/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4596 - val_accuracy: 0.7687 - val_loss: 0.5076\n",
      "Epoch 138/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8298 - loss: 0.4493 - val_accuracy: 0.6837 - val_loss: 0.7694\n",
      "Epoch 139/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 0.5373 - val_accuracy: 0.7347 - val_loss: 0.6089\n",
      "Epoch 140/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8408 - loss: 0.3839 - val_accuracy: 0.7857 - val_loss: 0.5586\n",
      "Epoch 141/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.3444 - val_accuracy: 0.7823 - val_loss: 0.5345\n",
      "Epoch 142/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8491 - loss: 0.3494 - val_accuracy: 0.8095 - val_loss: 0.4829\n",
      "Epoch 143/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8442 - loss: 0.3805 - val_accuracy: 0.7993 - val_loss: 0.5418\n",
      "Epoch 144/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8276 - loss: 0.4213 - val_accuracy: 0.7721 - val_loss: 0.5664\n",
      "Epoch 145/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.3794 - val_accuracy: 0.8061 - val_loss: 0.4948\n",
      "Epoch 146/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.3433 - val_accuracy: 0.8265 - val_loss: 0.4155\n",
      "Epoch 147/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8599 - loss: 0.3351 - val_accuracy: 0.8231 - val_loss: 0.4607\n",
      "Epoch 148/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.3355 - val_accuracy: 0.8197 - val_loss: 0.4678\n",
      "Epoch 149/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.3437 - val_accuracy: 0.8197 - val_loss: 0.4412\n",
      "Epoch 150/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.2880 - val_accuracy: 0.8333 - val_loss: 0.4498\n",
      "Epoch 151/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8654 - loss: 0.3627 - val_accuracy: 0.7721 - val_loss: 0.5946\n",
      "Epoch 152/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4718 - val_accuracy: 0.8027 - val_loss: 0.5368\n",
      "Epoch 153/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.3405 - val_accuracy: 0.7755 - val_loss: 0.5466\n",
      "Epoch 154/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8588 - loss: 0.3383 - val_accuracy: 0.7925 - val_loss: 0.5917\n",
      "Epoch 155/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8638 - loss: 0.3096 - val_accuracy: 0.7993 - val_loss: 0.5051\n",
      "Epoch 156/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8432 - loss: 0.3718 - val_accuracy: 0.8163 - val_loss: 0.5293\n",
      "Epoch 157/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8411 - loss: 0.4024 - val_accuracy: 0.7857 - val_loss: 0.5942\n",
      "Epoch 158/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8150 - loss: 0.4354 - val_accuracy: 0.7483 - val_loss: 0.6810\n",
      "Epoch 159/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.3811 - val_accuracy: 0.7619 - val_loss: 0.7433\n",
      "Epoch 160/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8394 - loss: 0.4344 - val_accuracy: 0.7585 - val_loss: 0.6378\n",
      "Epoch 161/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.4209 - val_accuracy: 0.7687 - val_loss: 0.5803\n",
      "Epoch 162/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8820 - loss: 0.3354 - val_accuracy: 0.7483 - val_loss: 0.5856\n",
      "Epoch 163/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.3505 - val_accuracy: 0.7449 - val_loss: 0.6004\n",
      "Epoch 164/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8320 - loss: 0.4069 - val_accuracy: 0.7959 - val_loss: 0.6030\n",
      "Epoch 165/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.4019 - val_accuracy: 0.7449 - val_loss: 0.6850\n",
      "Epoch 166/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.4215 - val_accuracy: 0.7687 - val_loss: 0.5529\n",
      "Epoch 167/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8462 - loss: 0.3423 - val_accuracy: 0.8095 - val_loss: 0.4975\n",
      "Epoch 168/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.3089 - val_accuracy: 0.7551 - val_loss: 0.5190\n",
      "Epoch 169/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8280 - loss: 0.3926 - val_accuracy: 0.8163 - val_loss: 0.4853\n",
      "Epoch 170/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 0.3488 - val_accuracy: 0.8129 - val_loss: 0.5536\n",
      "Epoch 171/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8733 - loss: 0.2907 - val_accuracy: 0.8231 - val_loss: 0.4656\n",
      "Epoch 172/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8920 - loss: 0.2773 - val_accuracy: 0.8197 - val_loss: 0.4904\n",
      "Epoch 173/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9057 - loss: 0.2604 - val_accuracy: 0.7959 - val_loss: 0.4782\n",
      "Epoch 174/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.3708 - val_accuracy: 0.7993 - val_loss: 0.6262\n",
      "Epoch 175/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8204 - loss: 0.4584 - val_accuracy: 0.8061 - val_loss: 0.5621\n",
      "Epoch 176/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.3175 - val_accuracy: 0.7653 - val_loss: 0.5831\n",
      "Epoch 177/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8361 - loss: 0.4250 - val_accuracy: 0.7347 - val_loss: 0.6866\n",
      "Epoch 178/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8104 - loss: 0.4468 - val_accuracy: 0.7517 - val_loss: 0.5831\n",
      "Epoch 179/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8282 - loss: 0.3832 - val_accuracy: 0.7721 - val_loss: 0.5188\n",
      "Epoch 180/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8263 - loss: 0.3967 - val_accuracy: 0.7619 - val_loss: 0.5853\n",
      "Epoch 181/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8355 - loss: 0.3685 - val_accuracy: 0.7823 - val_loss: 0.5682\n",
      "Epoch 182/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.3431 - val_accuracy: 0.7313 - val_loss: 0.7328\n",
      "Epoch 183/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8192 - loss: 0.4636 - val_accuracy: 0.8333 - val_loss: 0.4909\n",
      "Epoch 184/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8872 - loss: 0.3081 - val_accuracy: 0.7959 - val_loss: 0.5160\n",
      "Epoch 185/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8716 - loss: 0.2998 - val_accuracy: 0.8231 - val_loss: 0.4486\n",
      "Epoch 186/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8916 - loss: 0.2845 - val_accuracy: 0.8299 - val_loss: 0.4436\n",
      "Epoch 187/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8941 - loss: 0.2388 - val_accuracy: 0.8537 - val_loss: 0.4106\n",
      "Epoch 188/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8814 - loss: 0.2800 - val_accuracy: 0.8163 - val_loss: 0.5501\n",
      "Epoch 189/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3077 - val_accuracy: 0.7211 - val_loss: 0.6408\n",
      "Epoch 190/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.4122 - val_accuracy: 0.7891 - val_loss: 0.5144\n",
      "Epoch 191/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.3192 - val_accuracy: 0.7687 - val_loss: 0.5617\n",
      "Epoch 192/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.2558 - val_accuracy: 0.7857 - val_loss: 0.4520\n",
      "Epoch 193/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8703 - loss: 0.3138 - val_accuracy: 0.7857 - val_loss: 0.6747\n",
      "Epoch 194/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8895 - loss: 0.2912 - val_accuracy: 0.8231 - val_loss: 0.5197\n",
      "Epoch 195/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9038 - loss: 0.2809 - val_accuracy: 0.7959 - val_loss: 0.5612\n",
      "Epoch 196/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8779 - loss: 0.3009 - val_accuracy: 0.8231 - val_loss: 0.4875\n",
      "Epoch 197/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.2690 - val_accuracy: 0.8333 - val_loss: 0.4448\n",
      "Epoch 198/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 0.2703 - val_accuracy: 0.8333 - val_loss: 0.4388\n",
      "Epoch 199/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9152 - loss: 0.2298 - val_accuracy: 0.8333 - val_loss: 0.4897\n",
      "Epoch 200/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2630 - val_accuracy: 0.8265 - val_loss: 0.4171\n",
      "Epoch 201/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.3087 - val_accuracy: 0.8231 - val_loss: 0.5283\n",
      "Epoch 202/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8761 - loss: 0.3207 - val_accuracy: 0.7619 - val_loss: 0.4940\n",
      "Epoch 203/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.3122 - val_accuracy: 0.7959 - val_loss: 0.5623\n",
      "Epoch 204/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8737 - loss: 0.2902 - val_accuracy: 0.8503 - val_loss: 0.4084\n",
      "Epoch 205/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9089 - loss: 0.2358 - val_accuracy: 0.8333 - val_loss: 0.4149\n",
      "Epoch 206/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8940 - loss: 0.2414 - val_accuracy: 0.7959 - val_loss: 0.6805\n",
      "Epoch 207/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.3980 - val_accuracy: 0.8061 - val_loss: 0.4269\n",
      "Epoch 208/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8959 - loss: 0.2513 - val_accuracy: 0.8673 - val_loss: 0.3970\n",
      "Epoch 209/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9114 - loss: 0.2256 - val_accuracy: 0.8571 - val_loss: 0.4074\n",
      "Epoch 210/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.2251 - val_accuracy: 0.8163 - val_loss: 0.4106\n",
      "Epoch 211/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.2276 - val_accuracy: 0.8129 - val_loss: 0.5117\n",
      "Epoch 212/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9129 - loss: 0.2181 - val_accuracy: 0.8299 - val_loss: 0.4200\n",
      "Epoch 213/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.2098 - val_accuracy: 0.8707 - val_loss: 0.3791\n",
      "Epoch 214/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2078 - val_accuracy: 0.8469 - val_loss: 0.4359\n",
      "Epoch 215/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8824 - loss: 0.2843 - val_accuracy: 0.7279 - val_loss: 0.6027\n",
      "Epoch 216/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8310 - loss: 0.3776 - val_accuracy: 0.7449 - val_loss: 0.5774\n",
      "Epoch 217/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8759 - loss: 0.3006 - val_accuracy: 0.7857 - val_loss: 0.5739\n",
      "Epoch 218/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8800 - loss: 0.2841 - val_accuracy: 0.8333 - val_loss: 0.4323\n",
      "Epoch 219/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8984 - loss: 0.2712 - val_accuracy: 0.8163 - val_loss: 0.5803\n",
      "Epoch 220/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8715 - loss: 0.3284 - val_accuracy: 0.7789 - val_loss: 0.7304\n",
      "Epoch 221/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8708 - loss: 0.4013 - val_accuracy: 0.7653 - val_loss: 0.6112\n",
      "Epoch 222/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.3434 - val_accuracy: 0.8435 - val_loss: 0.4675\n",
      "Epoch 223/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8916 - loss: 0.2587 - val_accuracy: 0.8639 - val_loss: 0.4523\n",
      "Epoch 224/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9075 - loss: 0.2367 - val_accuracy: 0.8639 - val_loss: 0.4662\n",
      "Epoch 225/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8840 - loss: 0.2748 - val_accuracy: 0.7857 - val_loss: 0.5924\n",
      "Epoch 226/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8940 - loss: 0.2860 - val_accuracy: 0.8435 - val_loss: 0.4482\n",
      "Epoch 227/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2399 - val_accuracy: 0.8503 - val_loss: 0.4330\n",
      "Epoch 228/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8956 - loss: 0.2666 - val_accuracy: 0.8299 - val_loss: 0.4909\n",
      "Epoch 229/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8447 - loss: 0.4019 - val_accuracy: 0.8095 - val_loss: 0.5349\n",
      "Epoch 230/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8747 - loss: 0.2911 - val_accuracy: 0.8435 - val_loss: 0.4624\n",
      "Epoch 231/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2458 - val_accuracy: 0.8401 - val_loss: 0.4387\n",
      "Epoch 232/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8944 - loss: 0.2361 - val_accuracy: 0.8299 - val_loss: 0.4697\n",
      "Epoch 233/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.2048 - val_accuracy: 0.8231 - val_loss: 0.5409\n",
      "Epoch 234/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.2714 - val_accuracy: 0.8197 - val_loss: 0.5194\n",
      "Epoch 235/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.2403 - val_accuracy: 0.8095 - val_loss: 0.5413\n",
      "Epoch 236/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2447 - val_accuracy: 0.8469 - val_loss: 0.5109\n",
      "Epoch 237/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9123 - loss: 0.2208 - val_accuracy: 0.8265 - val_loss: 0.5719\n",
      "Epoch 238/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9007 - loss: 0.2459 - val_accuracy: 0.8095 - val_loss: 0.5956\n",
      "Epoch 239/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8946 - loss: 0.2532 - val_accuracy: 0.8571 - val_loss: 0.4340\n",
      "Epoch 240/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.2008 - val_accuracy: 0.8333 - val_loss: 0.5148\n",
      "Epoch 241/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9214 - loss: 0.2047 - val_accuracy: 0.8367 - val_loss: 0.4715\n",
      "Epoch 242/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8892 - loss: 0.2890 - val_accuracy: 0.8129 - val_loss: 0.5396\n",
      "Epoch 243/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8725 - loss: 0.3106 - val_accuracy: 0.8401 - val_loss: 0.4781\n",
      "Epoch 244/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.1994 - val_accuracy: 0.8401 - val_loss: 0.4247\n",
      "Epoch 245/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.2356 - val_accuracy: 0.8435 - val_loss: 0.4639\n",
      "Epoch 246/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.2369 - val_accuracy: 0.8197 - val_loss: 0.4844\n",
      "Epoch 247/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2269 - val_accuracy: 0.8231 - val_loss: 0.4588\n",
      "Epoch 248/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9140 - loss: 0.2154 - val_accuracy: 0.8333 - val_loss: 0.4860\n",
      "Epoch 249/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.2176 - val_accuracy: 0.8129 - val_loss: 0.5674\n",
      "Epoch 250/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.3470 - val_accuracy: 0.8367 - val_loss: 0.4597\n",
      "Epoch 251/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8977 - loss: 0.2593 - val_accuracy: 0.8231 - val_loss: 0.5082\n",
      "Epoch 252/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8835 - loss: 0.3388 - val_accuracy: 0.8299 - val_loss: 0.4992\n",
      "Epoch 253/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8745 - loss: 0.2900 - val_accuracy: 0.8265 - val_loss: 0.5089\n",
      "Epoch 254/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.3116 - val_accuracy: 0.7721 - val_loss: 0.6800\n",
      "Epoch 255/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.4106 - val_accuracy: 0.7585 - val_loss: 0.6344\n",
      "Epoch 256/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8801 - loss: 0.2907 - val_accuracy: 0.8129 - val_loss: 0.5494\n",
      "Epoch 257/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.2472 - val_accuracy: 0.8231 - val_loss: 0.5095\n",
      "Epoch 258/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.2355 - val_accuracy: 0.8163 - val_loss: 0.5624\n",
      "Epoch 259/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.2874 - val_accuracy: 0.7653 - val_loss: 0.6579\n",
      "Epoch 260/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7725 - loss: 0.4974 - val_accuracy: 0.7347 - val_loss: 0.7216\n",
      "Epoch 261/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7946 - loss: 0.4863 - val_accuracy: 0.7619 - val_loss: 0.6731\n",
      "Epoch 262/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8203 - loss: 0.4342 - val_accuracy: 0.7721 - val_loss: 0.6381\n",
      "Epoch 263/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.3697 - val_accuracy: 0.7721 - val_loss: 0.6364\n",
      "Epoch 264/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8300 - loss: 0.3980 - val_accuracy: 0.7109 - val_loss: 0.6230\n",
      "Epoch 265/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.3744 - val_accuracy: 0.7959 - val_loss: 0.5887\n",
      "Epoch 266/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8446 - loss: 0.3564 - val_accuracy: 0.7517 - val_loss: 0.6398\n",
      "Epoch 267/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8323 - loss: 0.3892 - val_accuracy: 0.7619 - val_loss: 0.6741\n",
      "Epoch 268/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8476 - loss: 0.3601 - val_accuracy: 0.7177 - val_loss: 0.6091\n",
      "Epoch 269/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7764 - loss: 0.5088 - val_accuracy: 0.7653 - val_loss: 0.6633\n",
      "Epoch 270/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8302 - loss: 0.4305 - val_accuracy: 0.7211 - val_loss: 0.6860\n",
      "Epoch 271/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8423 - loss: 0.3677 - val_accuracy: 0.7721 - val_loss: 0.6326\n",
      "Epoch 272/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8042 - loss: 0.4738 - val_accuracy: 0.7721 - val_loss: 0.6150\n",
      "Epoch 273/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8406 - loss: 0.4012 - val_accuracy: 0.7551 - val_loss: 0.5988\n",
      "Epoch 274/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8408 - loss: 0.3826 - val_accuracy: 0.7585 - val_loss: 0.6207\n",
      "Epoch 275/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8648 - loss: 0.3291 - val_accuracy: 0.7959 - val_loss: 0.5974\n",
      "Epoch 276/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8745 - loss: 0.3322 - val_accuracy: 0.7857 - val_loss: 0.6481\n",
      "Epoch 277/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8779 - loss: 0.3131 - val_accuracy: 0.7415 - val_loss: 0.6395\n",
      "Epoch 278/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8500 - loss: 0.3580 - val_accuracy: 0.7211 - val_loss: 0.7407\n",
      "Epoch 279/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8121 - loss: 0.4575 - val_accuracy: 0.7449 - val_loss: 0.6487\n",
      "Epoch 280/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.4476 - val_accuracy: 0.7551 - val_loss: 0.5944\n",
      "Epoch 281/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8351 - loss: 0.3937 - val_accuracy: 0.7245 - val_loss: 0.6443\n",
      "Epoch 282/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.3779 - val_accuracy: 0.7721 - val_loss: 0.6431\n",
      "Epoch 283/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8348 - loss: 0.3610 - val_accuracy: 0.7823 - val_loss: 0.5935\n",
      "Epoch 284/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8628 - loss: 0.3485 - val_accuracy: 0.7721 - val_loss: 0.6495\n",
      "Epoch 285/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8484 - loss: 0.3564 - val_accuracy: 0.7789 - val_loss: 0.5898\n",
      "Epoch 286/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8524 - loss: 0.3489 - val_accuracy: 0.7551 - val_loss: 0.6999\n",
      "Epoch 287/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8621 - loss: 0.3655 - val_accuracy: 0.7449 - val_loss: 0.6850\n",
      "Epoch 288/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8334 - loss: 0.3956 - val_accuracy: 0.7857 - val_loss: 0.6159\n",
      "Epoch 289/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8686 - loss: 0.3176 - val_accuracy: 0.7551 - val_loss: 0.5595\n",
      "Epoch 290/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8588 - loss: 0.3296 - val_accuracy: 0.7381 - val_loss: 0.7570\n",
      "Epoch 291/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8718 - loss: 0.3481 - val_accuracy: 0.7687 - val_loss: 0.6569\n",
      "Epoch 292/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8418 - loss: 0.3713 - val_accuracy: 0.7041 - val_loss: 0.8726\n",
      "Epoch 293/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8162 - loss: 0.4614 - val_accuracy: 0.7687 - val_loss: 0.6496\n",
      "Epoch 294/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8503 - loss: 0.3501 - val_accuracy: 0.7687 - val_loss: 0.5948\n",
      "Epoch 295/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8674 - loss: 0.3296 - val_accuracy: 0.7823 - val_loss: 0.5969\n",
      "Epoch 296/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.3144 - val_accuracy: 0.7721 - val_loss: 0.5844\n",
      "Epoch 297/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8707 - loss: 0.3107 - val_accuracy: 0.7619 - val_loss: 0.5992\n",
      "Epoch 298/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8653 - loss: 0.3192 - val_accuracy: 0.7959 - val_loss: 0.5951\n",
      "Epoch 299/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8564 - loss: 0.3500 - val_accuracy: 0.7347 - val_loss: 0.8767\n",
      "Epoch 300/300\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7865 - loss: 0.5354 - val_accuracy: 0.7687 - val_loss: 0.6178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2453a55d7c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 모델 컴파일 및 학습\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "es = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3, mode = 'auto')\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=300, batch_size=32, callbacks=es)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=300, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1736498705187,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "OCB8taP2yavC",
    "outputId": "c18c1b7b-de05-4ffb-a0c5-14ab56503bfa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "output_model = './Model/LSTM.h5'\n",
    "model.save(output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1736817098363,
     "user": {
      "displayName": "신호용",
      "userId": "04424386186383145760"
     },
     "user_tz": -540
    },
    "id": "zWxhnnUcOYPs",
    "outputId": "de5babdf-b6f8-47a8-ec48-07c37aecb7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 정확도: 76.87%\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델 평가\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"검증 데이터 정확도: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
